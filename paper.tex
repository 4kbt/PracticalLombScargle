\documentclass[preprint]{aastex}
%\documentclass{emulateapj}


% has to be before amssymb it seems
%\usepackage{color,hyperref}
%\definecolor{linkcolor}{rgb}{0,0,0.5}
%\hypersetup{colorlinks=true,linkcolor=linkcolor,citecolor=linkcolor,
%            filecolor=linkcolor,urlcolor=linkcolor}
%\usepackage{amssymb,amsmath}

\usepackage{color}
\usepackage{url}
\usepackage{graphicx}
\graphicspath{{figures/}}

% For Python code
\usepackage{listings}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\lstset{language=Python,
        basicstyle=\footnotesize\ttfamily,
        showspaces=false,
        showstringspaces=false,
        tabsize=2,
        breaklines=false,
        breakatwhitespace=true,
        identifierstyle=\ttfamily,
        keywordstyle=\bfseries\color[rgb]{0.133,0.545,0.133},
        commentstyle=\color[rgb]{0.133,0.545,0.133},
        stringstyle=\color[rgb]{0.627,0.126,0.941},
    }

% Draft watermark:
%\usepackage{draftwatermark}
%\SetWatermarkLightness{0.9}
%\SetWatermarkScale{4}

% Some macros
\newcommand{\todo}[1]{{\color{red} [TODO: #1]}}
\newcommand{\foreign}[1]{{\it #1}}

\newcommand{\apriori}{\foreign{a priori}}
\newcommand{\adhoc}{\foreign{ad hoc}}
\newcommand{\etal}{\foreign{et\,al.}}
\newcommand{\etc}{\foreign{etc.}}

\newcommand{\Fig}[1]{Figure~\ref{fig:#1}}
\newcommand{\fig}[1]{\Fig{#1}}
\newcommand{\figlabel}[1]{\label{fig:#1}}
\newcommand{\Eq}[1]{Equation~(\ref{eq:#1})}
\newcommand{\eq}[1]{\Eq{#1}}
\newcommand{\eqs}[2]{Equations~(\ref{eq:#1})-(\ref{eq:#2})}
\newcommand{\eqlabel}[1]{\label{eq:#1}}
\newcommand{\Sect}[1]{Section~\ref{sect:#1}}
\newcommand{\sect}[1]{\Sect{#1}}
\newcommand{\sects}[1]{Sections~#1}
\newcommand{\App}[1]{Appendix~\ref{sect:#1}}
\newcommand{\app}[1]{\App{#1}}
\newcommand{\sectlabel}[1]{\label{sect:#1}}

\usepackage[normalem]{ulem}
\newcommand{\new}[1]{{\color{red} #1}}
\newcommand{\old}[1]{{\sout{#1}}}


\begin{document}

\title{Practical Considerations for Lomb-Scargle Periodic Analysis}

\newcommand{\escience}{*}
\newcommand{\uwastro}{+}
\author{Jacob T. VanderPlas\altaffilmark{\escience}}
\altaffiltext{\escience}{eScience Institute, University of Washington}


\begin{abstract}
An introduction to practical aspects of the use of Lomb-Scargle-type algorithms for periodic analysis.
\end{abstract}

\keywords{
    methods: data analysis ---
    methods: statistical
}

\section{Introduction}
\sectlabel{introduction}

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{fig01_LINEAR_data}
\caption{Observed light curve from LINEAR object ID 11375941
    \figlabel{LINEAR_data}.
}
\end{figure}


\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{fig02_LINEAR_PSD}
\caption{{\it Left panel:} the Lomb-Scargle periodogram computed from the data
    shown in \fig{LINEAR_data}, with an inset detailing the interesting region.
    {\it Right panel:} the input data in \fig{LINEAR_data}, folded over the
    2.58-hour period to show the coherent periodic variability.
    \figlabel{LINEAR_power}
}
\end{figure}

The Lomb-Scargle periodogram \citep{Lomb76, Scargle82}
is a well-known algorithm for detecting periodicity
in unevenly-sampled time-series, particularly within the astronomy community.
For example, consider the data showing in \Fig{LINEAR_data}.
This is an irregularly-sampled timeseries showing a single object from the
LINEAR survey, with magnitude measured 280 times over the course of five and
a half years.

It is clear that this object varies with an amplitude of around 0.6 magnitudes.
Computing the Lomb-Scargle periodogram for the data gives us a measure of the
power as a function of period of oscillation (\fig{LINEAR_power}, left)\footnote{
This periodogram was computed using tools in the AstroPy project \citep{Astropy2013};
code is available at \url{http://github.com/jakevdp/PracticalLombScargle/}
}, from
which we can determine the period of oscillation of approximately 2.58 hours.
The right panel of \fig{LINEAR_power} shows a folded visualization of
the same data as \fig{LINEAR_data} -- i.e.{} plotted as a function of phase
rather than time.

Often this is exactly how the Lomb-Scargle periodogram is presented: as a clean,
well-defined procedure to detect the periodic component in an unevenly-sampled dataset.
In practice, however, there are a number of subtle issues that must be considered
when applying a Lomb-Scargle analysis to real-world datasets, and I have found
that these are rarely presented together at an introductory level.
This paper seeks to fill that gap, and provide a practical, semi-technical
guide to the effective use of the Lomb-Scargle method of periodic analysis.


\section{Background: Continuous Fourier Transform}

To understand what the Lomb-Scargle periodogram is doing, we will first step
back and review the subject of Fourier analysis of continuous signals.
If we have a continuously-defined signal $g(t)$, we can compute its Fourier
transform $\hat{g}(f)$ using the following integral:
\begin{equation}
    \hat{g}(f) \equiv \int_{-\infty}^\infty g(t) e^{-2\pi i f t} dt
    \eqlabel{FT-def}
\end{equation}
The inverse relationship is given by:
\begin{equation}
    g(t) \equiv \int_{-\infty}^\infty \hat{g}(f) e^{+2\pi i f t} df
    \eqlabel{IFT-def}
\end{equation}
This can be straightforwardly confirmed using the linearity of integration and
the integral definition of the Dirac delta function.
For convenience below, we will define the Fourier transform operator $\mathcal{F}$,
such that
\begin{eqnarray}
    \mathcal{F}\{g\} &=& \hat{g} \\
    \mathcal{F}^{-1}\{\hat{g}\} &=& g
\end{eqnarray}

\subsection{Motivating the Power Spectral Density}

If you explore the properties of the Fourier transform, you will discover
a couple important properties:

\begin{description}
\item[The Fourier Transform of a Sine wave is a delta function at its frequency.]
    That is, if $g(t) = \sin(2\pi f_0 t)$, then
    \begin{equation}
        \hat{g}(f) \propto \delta(f - f_0) - \delta(f + f_0)
    \end{equation}
\item[The Fourier Transform is a Linear Operation.]
    This means that for functions $a$ and $b$ and scalar $A$,
    \begin{eqnarray}
        \mathcal{F}(a + b) &=& \mathcal{F}(a) + \mathcal{F}(b) \\
        \mathcal{F}(A \cdot a) &=& A\cdot\mathcal{F}(a).
    \end{eqnarray}
    These properties follow straightforwardly from the linearity of integration.
\item[The Fourier Transform of a time-shifted function is unchanged up to a phase.]
    That is, if $g_\tau(t) = g(t - \tau)$, then
    \begin{equation}
        \hat{g}_\tau(f) = e^{-2\pi i f \tau}\hat{g}(f)
    \end{equation}
    This can be confirmed via a change of variables in \eq{FT-def}.
\end{description}

Taken together, what this tells us is that if we define the spectral density
\begin{equation}
    \mathcal{P}(g) \equiv \left|\mathcal{F}(g)\right|^2
\end{equation}
we have a quantity that is {\it insensitive to time-shifts} and consists of a
{\it delta function for each sinusoidal frequency within the data}. In other
words, the spectral density {\it P} measures ...

Because of the first two properties, we see that the Fourier transform can essentially
extract sinusoidal components within a signal:


\begin{description}

\item[Convolution Theorem.]
    The convolution theorem states that the
    Fourier transform of a convolution is a product of the Fourier transforms:
    \begin{equation}
      \mathcal{F}\{g \ast h\} = \mathcal{F}\{g\}\mathcal{F}\{h\}
    \end{equation}
    where the convlution operator $\ast$ is defined by
    \begin{equation}
      \{g \ast h\}(t) \equiv \int_{-\infty}^\infty g(t - \tau) h(\tau) d\tau.
    \end{equation}
    This can be confirmed via the linearity of integration and the integral
    definition of the Dirac delta function.

\item[The Fourier Transform of a Gaussian is a Gaussian.]
    The Gaussian function is defined as
    \begin{equation}
    G(t;\sigma) \propto \exp\left[\frac{-t^2}{2\sigma^2}\right].
    \end{equation}
    The Fourier transform of a Gaussian is another Gaussian:
    \begin{equation}
    \mathcal{F}\{G(t;\sigma)\} \propto G(f; \sigma_f)
    \end{equation}
    where $\sigma_f = (2\pi\sigma)^{-1}$. This can be shown by completing the
    square within the integrand.
\end{description}

\subsubsection{The Convolution Theorem}

The Fourier transform is central to an identity known as {\it the convolution theorem}.
The convolution of two functions $g(t)$ and $h(t)$ is itself a function of $t$, denoted $\{g \ast h\}(t)$, and is defined as


The convolution theorem states that the Fourier transform of a convolution is equal to the product of Fourier transforms; that is,


This property can also be shown (relatively) straightforwardly from the convolution and Fourier transform definitions.

\subsubsection{$\mathcal{F}$ of a Gaussian is a Gaussian}
One of the special functions under a Fourier transform is the Gaussian distribution:

\begin{equation}
    g(t; \mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left[\frac{- (x - \mu)^2}{2\sigma^2}\right]
\end{equation}, which is proportional to


\subsubsection{$\mathcal{F}$ of a Periodic Function is a Delta Function}

A particularly special function in the complex exponential, $e^{2\pi i\nu_0 t} \equiv \cos(2\pi \nu_0 t) + i\sin(2\pi\nu_0 t)$, which has the Fourier transform $\mathcal{F}\{e^{2\pi i\nu_0 t}\} = \delta(\nu - \nu_0)$, which follows directly from the definition of the Dirac delta function:

\begin{equation}
  \delta(\nu) \equiv \int_{-\infty}^\infty e^{-2\pi i\nu t}dt
\end{equation}

Similarly, if we have a signal composed of a sum of complex exponentials, the linearity of the Fourier transform assures that the transform is simply a sum of delta functions:
\begin{equation}
  \mathcal{F}\left\{ \sum_{n=1}^N e^{-2\pi i \nu_n t} \right\} = \sum_{n=1}^N \delta(\nu - \nu_n)
\end{equation}
This result shows the sense in which a Fourier transform is an ideal measure of periodicity: the Fourier transform pulls-out and identifies the individual periodic components of any input.

\subsection{Fourier Power}

Using the above definitions, it is straightforward to show that a time-offset in a function leads to a multiplicative phase in the Fourier transform; that is, if
\begin{equation}
  g_\tau(t) \equiv g(t - \tau)
\end{equation}
then
\begin{equation}
  \mathcal{F}\{g_\tau\} = e^{-2\pi i \nu \tau}\mathcal{F}\{g\}
\end{equation}
Because the phase merely represents the chosen coordinate system, we'd like to remove it for spectral analysis.
One way to do this is to compute the power spectral density, which is proportional to \todo{const of proportionality?} the squared modulus of the Fourier Transform:
\begin{equation}
  P\{g\} \propto \left| \mathcal{F}\{g\} \right|^2.
\end{equation}
Because the modulus of a phase is equal to unity, the resulting measure is unchanged under time-translations in $g(t)$, and $P\{g\} = P\{g_\tau\}$ for any time-shift $\tau$.

\begin{itemize}
\item Some examples of functions, their transforms, and their power.
\end{itemize}

\subsection{Effect of Window Functions}

\begin{itemize}
\item convolution function and windowing
\end{itemize}

\section{From Idealistic to Realistic}

All of the above theory is beautiful and elegant, but when the theory meets the real world things get a bit more messy.
In particular, we rarely (if ever) are able to measure continuous functions like $g(t)$, but instead measure discrete realizations of the underlying function at a finite number of particular times $t_n$.
These discrete observations are effectively a window function over our data, and as we saw above, the presence of such a window function will propagate through our computation of the Fourier power!
The quantitative result of this windowning depends on the exact nature of the observation pattern; we will first consider the somewhat simpler case of evenly-spaced discrete data.

\subsection{Evenly-Spaced Discrete Data: the Schuster Periodogram}

Let's first consider the case of a large series of evenly-spaced observations.
Discrete samples can


\begin{itemize}
\item Evenly-spaced delta functions $\to$ evenly-spaced delta in frequency, separated by nyquist
\end{itemize}

\subsection{Unevenly-Spaced Discrete Data: the Lomb-Scargle Periodogram}


\begin{itemize}
\item Unevenly-spaced delta functions: no cancelations, and so window is generally {\it infinitely} wide.
\item Least-squares equivalence of Lomb-Scargle
\end{itemize}

\section{What Frequency Grid to Use?}

\begin{itemize}
\item Follow discussion from gatspy documentation
\end{itemize}

\section{Reporting errors in Frequency: Uncertainty vs. Precision}

\begin{itemize}
\item Talk about peak width and False Alarm Probability; recommend bootstrap (show example of when analytic FAP fails?)
\end{itemize}

\section{Algorithmic Considerations}

\begin{itemize}
\item Talk about Press \& Rybicki method; show some benchmarks.
\end{itemize}

\section{Generalizations \& Challenges}

\begin{itemize}
\item Multiterm makes the true period fit better, but also bumps the background noise.
\end{itemize}

\citet{VanderPlas2015}

\bibliographystyle{apj}
\bibliography{paper}

\end{document}
